{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d281a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from transformers import BertForQuestionAnswering, BertModel\n",
    "from transformers import BertTokenizer\n",
    "import tqdm\n",
    "tqdmn = tqdm.notebook.tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.cross_decomposition import CCA\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c40d8068-f609-444b-a56f-b9c982ae09d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/aditkulk/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c98f2f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../original_data/semeval14/restaurant/\"\n",
    "with open(str(path) + \"semeval_14_restaurant_sentence_dictionary_train_pairs_pseudo.pickle\", \"rb\") as handle:\n",
    "    train14 = pickle.load(handle)\n",
    "\n",
    "# path = \"../../original_data/semeval15/\"\n",
    "# with open(str(path) + \"semeval_15_restaurant_sentence_dictionary_train_pairs_pseudo.pickle\", \"rb\") as handle:\n",
    "#     train15 = pickle.load(handle)\n",
    "\n",
    "path = \"../../original_data/semeval16/\"\n",
    "with open(str(path) + \"semeval_16_restaurant_sentence_dictionary_train_pairs_pseudo.pickle\", \"rb\") as handle:\n",
    "    train16 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ca32234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end_index(input_ids, solution):\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    start_boolean = False\n",
    "    end_boolean = False\n",
    "    for i in range(0, len(tokens)):\n",
    "        if tokens[i] == solution[0]:\n",
    "            start_index = i\n",
    "            start_boolean = True\n",
    "            break\n",
    "    for i in range(0, len(tokens)):\n",
    "        if tokens[i] == solution[-1]:\n",
    "            end_index = i\n",
    "            end_boolean = True\n",
    "            break\n",
    "    if (start_boolean == True) and (end_boolean == True):\n",
    "        return start_index, end_index\n",
    "    elif (start_boolean == False) and (end_boolean == True):\n",
    "        for i in range(0, len(tokens)):\n",
    "            if tokens[i].replace('##', '') in solution[0]:\n",
    "                start_index = i\n",
    "                start_boolean = True\n",
    "                break\n",
    "        return start_index, end_index\n",
    "    elif (start_boolean == True) and (end_boolean == False):\n",
    "        for i in range(0, len(tokens)):\n",
    "            if tokens[i].replace('##', '') in solution[-1]:\n",
    "                end_index = i\n",
    "                end_boolean = True\n",
    "                break\n",
    "        return start_index, end_index\n",
    "    elif (start_boolean == False) and (end_boolean == False):\n",
    "        for i in range(0, len(tokens)):\n",
    "            if tokens[i].replace('##', '') in solution[0]:\n",
    "                start_index = i\n",
    "                start_boolean = True\n",
    "                break\n",
    "        for i in range(0, len(tokens)):\n",
    "            if tokens[i].replace('##', '') in solution[-1]:\n",
    "                end_index = i\n",
    "                end_boolean = True\n",
    "                break\n",
    "        return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7429355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class construct_dataset(Dataset):\n",
    "    def __init__(self, question, text, answer, question_opinion, text_opinion, answer_opinion):\n",
    "        self.question = question\n",
    "        self.text = text\n",
    "        self.answer = answer\n",
    "        self.question_opinion = question_opinion\n",
    "        self.text_opinion = text_opinion\n",
    "        self.answer_opinion = answer_opinion\n",
    "    def __len__(self):\n",
    "        return len(self.question)\n",
    "    def __getitem__(self, idx):\n",
    "        query = self.question[idx].lower()\n",
    "        sent = self.text[idx].lower()\n",
    "        input_ids = tokenizer.encode(query, sent)\n",
    "        sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "        num_seg_a = sep_idx+1\n",
    "        num_seg_b = len(input_ids) - num_seg_a\n",
    "        segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "        \n",
    "        query_opinion = self.question_opinion[idx].lower()\n",
    "        sent_opinion = self.text_opinion[idx].lower()\n",
    "        input_ids_opinion = tokenizer.encode(query_opinion, sent_opinion)\n",
    "        sep_idx_opinion = input_ids_opinion.index(tokenizer.sep_token_id)\n",
    "        num_seg_a_opinion = sep_idx_opinion+1\n",
    "        num_seg_b_opinion = len(input_ids_opinion) - num_seg_a_opinion\n",
    "        segment_ids_opinion = [0]*num_seg_a_opinion + [1]*num_seg_b_opinion\n",
    "        \n",
    "        term_input_ids = tokenizer.encode(sent)\n",
    "        term_sep_idx = term_input_ids.index(tokenizer.sep_token_id)\n",
    "        term_num_seg_a = term_sep_idx+1\n",
    "        term_num_seg_b = len(term_input_ids) - term_num_seg_a\n",
    "        term_segment_ids = [0]*term_num_seg_a + [1]*term_num_seg_b\n",
    "        \n",
    "        opinion_input_ids = tokenizer.encode(sent_opinion)\n",
    "        opinion_sep_idx = opinion_input_ids.index(tokenizer.sep_token_id)\n",
    "        opinion_num_seg_a = opinion_sep_idx+1\n",
    "        opinion_num_seg_b = len(opinion_input_ids) - opinion_num_seg_a\n",
    "        opinion_segment_ids = [0]*opinion_num_seg_a + [1]*opinion_num_seg_b\n",
    "\n",
    "        if self.answer[idx] not in ['[CLS]']:\n",
    "            solution = self.answer[idx].lower().split(\" \")\n",
    "        else:\n",
    "            solution = self.answer[idx].split(\" \")\n",
    "        \n",
    "        if self.answer_opinion[idx] not in ['[CLS]']:\n",
    "            solution_opinion = self.answer_opinion[idx].lower().split(\" \")\n",
    "        else:\n",
    "            solution_opinion = self.answer_opinion[idx].split(\" \")\n",
    "        \n",
    "        tokens_list = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "        start_index, end_index = get_start_end_index(input_ids, solution)\n",
    "        term_start_index, term_end_index = get_start_end_index(term_input_ids, solution)\n",
    "        \n",
    "        start_index_opinion, end_index_opinion = get_start_end_index(input_ids_opinion, solution_opinion)\n",
    "        opinion_start_index, opinion_end_index = get_start_end_index(opinion_input_ids, solution_opinion)\n",
    "        \n",
    "        sample = {\"input_ids\": torch.tensor(input_ids), \"segment_ids\": torch.tensor(segment_ids), \"start_index\": torch.tensor(start_index), \"end_index\": torch.tensor(end_index),\n",
    "                 \"term_input_ids\": torch.tensor(term_input_ids), \"term_segment_ids\": torch.tensor(term_segment_ids), \"term_start_index\": torch.tensor(term_start_index),\n",
    "                  \"term_end_index\": torch.tensor(term_end_index),\n",
    "                 \"input_ids_opinion\": torch.tensor(input_ids_opinion), \"segment_ids_opinion\": torch.tensor(segment_ids_opinion), \"start_index_opinion\": torch.tensor(start_index_opinion), \"end_index_opinion\": torch.tensor(end_index_opinion),\n",
    "                 \"opinion_input_ids\": torch.tensor(opinion_input_ids), \"opinion_segment_ids\": torch.tensor(opinion_segment_ids), \"opinion_start_index\": torch.tensor(opinion_start_index),\n",
    "                  \"opinion_end_index\": torch.tensor(opinion_end_index)}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fae6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dictionary = {}\n",
    "counter = 0\n",
    "for i in range(0, len(train14)):\n",
    "    train_dictionary[counter] = train14[i]\n",
    "    counter = counter + 1\n",
    "\n",
    "for i in range(0, len(train15)):\n",
    "    train_dictionary[counter] = train15[i]\n",
    "    counter = counter + 1\n",
    "\n",
    "for i in range(0, len(train16)):\n",
    "    train_dictionary[counter] = train16[i]\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dcb7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = []\n",
    "question = []\n",
    "answer = []\n",
    "for j in range(0, len(train_dictionary)):\n",
    "    sentence.append(train_dictionary[j]['sentence'])\n",
    "    question.append(train_dictionary[j]['opinion'])\n",
    "    answer.append(train_dictionary[j]['term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b288fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_opinion = []\n",
    "question_opinion = []\n",
    "answer_opinion = []\n",
    "for j in range(0, len(train_dictionary)):\n",
    "    sentence_opinion.append(train_dictionary[j]['sentence'])\n",
    "    question_opinion.append(train_dictionary[j]['term'])\n",
    "    answer_opinion.append(train_dictionary[j]['opinion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf1eef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_version = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99deed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwolayerQA(nn.Module):\n",
    "\n",
    "    def __init__(self, device):\n",
    "\n",
    "        super(TwolayerQA, self).__init__()\n",
    "\n",
    "        self.bert_osae = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.bert_term = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.bert_asoe = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.bert_opinion = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.config = self.bert_osae.config\n",
    "        #print(self.config)\n",
    "        self.qa_outputs_osae = nn.Linear(self.config.hidden_size, 2)\n",
    "        self.qa_outputs_term = nn.Linear(self.config.hidden_size, 2)\n",
    "        self.qa_outputs_asoe = nn.Linear(self.config.hidden_size, 2)\n",
    "        self.qa_outputs_opinion = nn.Linear(self.config.hidden_size, 2)\n",
    "        #self.cca_loss_fn = cca_loss(outdim_size=self.config.hidden_size, use_all_singular_values=True, device=device)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None,term_token_type_ids=None, attention_mask=None, start_positions=None, end_positions=None, term_input_ids=None, term_attention_mask=None, term_start_positions=None, term_end_positions=None, input_ids_opinion=None, segment_ids_opinion=None, start_index_opinion=None,  end_index_opinion=None, opinion_input_ids=None, opinion_segment_ids=None, opinion_start_index=None, opinion_end_index=None):\n",
    "\n",
    "        output_osae = self.bert_osae(input_ids, token_type_ids, attention_mask)\n",
    "        term_output = self.bert_term(term_input_ids, term_token_type_ids, term_attention_mask)\n",
    "        \n",
    "        output_asoe = self.bert_asoe(input_ids_opinion, segment_ids_opinion, attention_mask)\n",
    "        opinion_output = self.bert_opinion(opinion_input_ids, opinion_segment_ids, term_attention_mask)\n",
    "        \n",
    "        logits = self.qa_outputs_osae(output_osae[0])\n",
    "        term_logits = self.qa_outputs_term(term_output[0])\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "        \n",
    "        term_start_logits, term_end_logits = term_logits.split(1, dim=-1)\n",
    "        term_start_logits = term_start_logits.squeeze(-1)\n",
    "        term_end_logits = term_end_logits.squeeze(-1)\n",
    "        \n",
    "        \n",
    "        logits_opinion = self.qa_outputs_asoe(output_asoe[0])\n",
    "        opinion_logits = self.qa_outputs_opinion(opinion_output[0])\n",
    "        start_logits_opinion, end_logits_opinion = logits_opinion.split(1, dim=-1)\n",
    "        start_logits_opinion = start_logits_opinion.squeeze(-1)\n",
    "        end_logits_opinion = end_logits_opinion.squeeze(-1)\n",
    "        \n",
    "        opinion_start_logits, opinion_end_logits = opinion_logits.split(1, dim=-1)\n",
    "        opinion_start_logits = opinion_start_logits.squeeze(-1)\n",
    "        opinion_end_logits = opinion_end_logits.squeeze(-1)\n",
    "\n",
    "        if start_positions is not None and end_positions is not None and term_start_positions is not None and term_end_positions is not None:\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            \n",
    "            if len(term_start_positions.size()) > 1:\n",
    "                term_start_positions = term_start_positions.squeeze(-1)\n",
    "            if len(term_end_positions.size()) > 1:\n",
    "                term_end_positions = term_end_positions.squeeze(-1)\n",
    "                \n",
    "            if len(start_index_opinion.size()) > 1:\n",
    "                start_index_opinion = start_index_opinion.squeeze(-1)\n",
    "            if len(end_index_opinion.size()) > 1:\n",
    "                end_index_opinion = end_index_opinion.squeeze(-1)\n",
    "            \n",
    "            if len(opinion_start_index.size()) > 1:\n",
    "                opinion_start_index = opinion_start_index.squeeze(-1)\n",
    "            if len(opinion_end_index.size()) > 1:\n",
    "                opinion_end_index = opinion_end_index.squeeze(-1)\n",
    "            \n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "            \n",
    "            term_loss_fct = CrossEntropyLoss()\n",
    "            term_start_loss = term_loss_fct(term_start_logits, term_start_positions)\n",
    "            term_end_loss = term_loss_fct(term_end_logits, term_end_positions)\n",
    "            term_total_loss = (term_start_loss + term_end_loss) / 2\n",
    "            \n",
    "\n",
    "            start_loss_opinion = loss_fct(start_logits_opinion, start_index_opinion)\n",
    "            end_loss_opinion = loss_fct(end_logits_opinion, end_index_opinion)\n",
    "            total_loss_opinion = (start_loss_opinion + end_loss_opinion) / 2\n",
    "            \n",
    "            \n",
    "            opinion_start_loss = term_loss_fct(opinion_start_logits, opinion_start_index)\n",
    "            opinion_end_loss = term_loss_fct(opinion_end_logits, opinion_end_index)\n",
    "            opinion_total_loss = (opinion_start_loss + opinion_end_loss) / 2\n",
    "            \n",
    "            return total_loss, term_total_loss, total_loss_opinion, opinion_total_loss, output_osae, term_output, output_asoe, opinion_output\n",
    "        else:\n",
    "            return start_logits, end_logits, term_start_logits, term_end_logits, start_logits_opinion, end_logits_opinion, opinion_start_logits, opinion_end_logits, output_osae, term_output, output_asoe, opinion_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74fa84a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = construct_dataset(question, sentence, answer, question_opinion, sentence_opinion, answer_opinion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4370e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577a394a9a7f4011a5c429fc4c66da2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Correlation score: -9.224195915301385e-18\n",
      "Epoch: 0 Average loss: 4.256232448203898\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d698c252c204b0eb230a4f5d73c991a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Correlation score: -8.57721498044378e-18\n",
      "Epoch: 1 Average loss: 2.272766076560734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bada41e303e4a9cbf809129a673e9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Correlation score: -1.821216092062867e-17\n",
      "Epoch: 2 Average loss: 1.847488086199013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48007e9bace54f3e95825add9cb473ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Correlation score: -1.5194892402252686e-17\n",
      "Epoch: 3 Average loss: 1.605052500520549\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2232d2fe897b477cb2d13d9a3499581b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Correlation score: -5.818589460468381e-20\n",
      "Epoch: 4 Average loss: 1.4561846811003507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63eefb766a9340a58875ff7b80bb8a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Correlation score: 7.62857805150247e-18\n",
      "Epoch: 5 Average loss: 1.3662635390663083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fce545c54234dfea5faad8716bd4b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Correlation score: 6.350072143087284e-18\n",
      "Epoch: 6 Average loss: 1.3108968865461421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26b6e31dcde44e984dedaf314a3dc60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Correlation score: 6.337539052367932e-18\n",
      "Epoch: 7 Average loss: 1.2710713833500205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45232f525d394c0b87a3cc8e1121e50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Correlation score: -3.6200138615520424e-19\n",
      "Epoch: 8 Average loss: 1.258945222024411\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a8c7536e5c41d2a74bb5b6f2bbd231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Correlation score: -1.5555276244555391e-18\n",
      "Epoch: 9 Average loss: 1.2297535902564272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130ccebcb6ac4401852a30dc448199b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Correlation score: 1.6929543049224221e-18\n",
      "Epoch: 10 Average loss: 1.212680793350148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9d4a4538dc4281b6d59a9625ce2eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Correlation score: 2.7307753823375647e-18\n",
      "Epoch: 11 Average loss: 1.1869790409726415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880035d2458f4b93b0217e913643ab4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 Correlation score: 9.798874377376015e-19\n",
      "Epoch: 12 Average loss: 1.2087137425280738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8d862071ef408598e003c5b0656059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 Correlation score: 6.073542670250871e-20\n",
      "Epoch: 13 Average loss: 1.1851139130344808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e79cba5330d4fb19a1ae323553e570f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 Correlation score: 1.8565472750385585e-18\n",
      "Epoch: 14 Average loss: 1.1665371355170486\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7e06602b6b40a4a9457cb6ebcbb7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 Correlation score: 1.973419044055314e-19\n",
      "Epoch: 15 Average loss: 1.1488159209635342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01bee2560c7462398aadd456c382a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 Correlation score: -2.0371964076360457e-18\n",
      "Epoch: 16 Average loss: 1.1780513909993204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63968b379024f718580af436c56d5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = optim.AdamW(params=model.parameters(), lr=1e-5)\n",
    "n_epochs = 18\n",
    "train_data = torch.utils.data.DataLoader(train_dataset, batch_size=1)\n",
    "previous_correlation = 0\n",
    "diff = 0\n",
    "correlation_result = []\n",
    "for epochs in range(n_epochs):\n",
    "    train_loss = []\n",
    "    current_loss = 0\n",
    "    for i, batch in enumerate(tqdmn(train_data)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        segment_ids = batch['segment_ids'].to(device)\n",
    "        start_index = batch['start_index'].to(device)\n",
    "        end_index = batch['end_index'].to(device)\n",
    "        term_input_ids = batch['term_input_ids'].to(device)\n",
    "        term_segment_ids = batch['term_segment_ids'].to(device)\n",
    "        term_start_index = batch['term_start_index'].to(device)\n",
    "        term_end_index = batch['term_end_index'].to(device)\n",
    "        \n",
    "        input_ids_opinion = batch['input_ids_opinion'].to(device)\n",
    "        segment_ids_opinion = batch['segment_ids_opinion'].to(device)\n",
    "        start_index_opinion = batch['start_index_opinion'].to(device)\n",
    "        end_index_opinion = batch['end_index_opinion'].to(device)\n",
    "        opinion_input_ids = batch['opinion_input_ids'].to(device)\n",
    "        opinion_segment_ids = batch['opinion_segment_ids'].to(device)\n",
    "        opinion_start_index = batch['opinion_start_index'].to(device)\n",
    "        opinion_end_index = batch['opinion_end_index'].to(device)\n",
    "        \n",
    "        total_loss, term_total_loss, total_loss_opinion, opinion_total_loss, output_osae, term_output, output_asoe, opinion_output = model(input_ids=input_ids, token_type_ids=segment_ids, start_positions=start_index, end_positions=end_index, term_input_ids=term_input_ids, term_token_type_ids=term_segment_ids, term_start_positions=term_start_index, term_end_positions=term_end_index,input_ids_opinion=input_ids_opinion, segment_ids_opinion=segment_ids_opinion, start_index_opinion=start_index_opinion,  end_index_opinion=end_index_opinion, opinion_input_ids=opinion_input_ids, opinion_segment_ids=opinion_segment_ids, opinion_start_index=opinion_start_index, opinion_end_index=opinion_end_index)\n",
    "        X = term_output[0].squeeze().detach().cpu()\n",
    "        Y = output_osae[0].squeeze()[-len(X):].detach().cpu()\n",
    "        cca = CCA(n_components=4)\n",
    "        cca.fit(X, Y)\n",
    "        X_c, Y_c = cca.transform(X, Y)\n",
    "        result = np.corrcoef(X_c.T, Y_c.T)[0,1]\n",
    "        \n",
    "        X = opinion_output[0].squeeze().detach().cpu()\n",
    "        Y = output_asoe[0].squeeze()[-len(X):].detach().cpu()\n",
    "        cca = CCA(n_components=4)\n",
    "        cca.fit(X, Y)\n",
    "        X_c, Y_c = cca.transform(X, Y)\n",
    "        result_2 = np.corrcoef(X_c.T, Y_c.T)[0,1]\n",
    "        \n",
    "        correlation = result + result_2\n",
    "        \n",
    "        correlation_result.append(correlation)\n",
    "        loss = total_loss + term_total_loss + total_loss_opinion + opinion_total_loss\n",
    "        loss.backward()\n",
    "        current_loss += loss.item()\n",
    "        if i % 8 == 0 and i > 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.append(current_loss / 8)\n",
    "            current_loss = 0\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    torch.save(model, 'ODAO_CCA_correlation_epoch_' + str(epochs))\n",
    "    \n",
    "    print(\"Epoch: \" + str(epochs) + \" Correlation score: \" + str(np.mean(correlation_result)))\n",
    "    \n",
    "    print(\"Epoch: \" + str(epochs) + \" Average loss: \" + str(np.mean(train_loss)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
